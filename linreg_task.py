# -*- coding: utf-8 -*-
"""LinReg_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YOVcIG2_JvAP5SH9dpkEf86AedPXahNN

# Линейная регрессия. Работа с признаками

## Описание задачи и загрузка данных
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""В этом задании мы рассмотрим различные аспекты построения линейной модели. Мы будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах. Описание можно посмотреть [здесь](https://www.kaggle.com/shivam2503/diamonds)."""

data = pd.read_csv('https://raw.githubusercontent.com/evgpat/edu_stepik_practical_ml/main/datasets/diamonds.csv')
data.head(5)

"""Посмотрим на типы столбцов."""

data.dtypes

"""Мы будем решать задачу предсказания цены бриллианта `price` в зависимости от его характеристик.

## Построение модели

### Задание 1

Есть ли в наборе данных пропущенные значения? Если да, удалите их.

Также выведите на экран число пропусков в каждом столбце.
"""

# your code here
# Число пропусков по каждому столбцу
na_counts = data.isna().sum()
print("Пропуски по столбцам:")
print(na_counts)

# Если есть пропуски — удалим строки с ними
n_before = len(data)
data = data.dropna()
n_after = len(data)

print(f"\nУдалено строк с пропусками: {n_before - n_after}")
print(f"Размер датасета после очистки: {data.shape}")

"""### Задача 2

Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)?  
Если да, то удалите их.
"""

# your code here
# Проверим наличие лишнего индекса
print(data.columns)

# Удалим ненужный столбец, если он есть
if 'Unnamed: 0' in data.columns:
    data = data.drop(columns=['Unnamed: 0'])
    print("Столбец 'Unnamed: 0' удалён.")
else:
    print("Лишних столбцов не найдено.")

print(f"После удаления осталось столбцов: {data.shape[1]}")

"""### Задание 3

Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Для следующих пунктов нам также потребуются корреляции между признаками.  
Выведите матрицу корреляций между всеми вещественными признаками и целевой переменной.

Какой вещественный признак коррелирует с целевой переменной больше всего?
"""

# your code here
# Вычислим корреляцию только для числовых признаков
corr_matrix = data.corr(numeric_only=True)

# Выведем матрицу корреляций
print("Матрица корреляций:")
print(corr_matrix)

# Отсортируем признаки по степени корреляции с ценой
corr_with_price = corr_matrix['price'].sort_values(ascending=False)
print("\nКорреляция признаков с целевой переменной 'price':")
print(corr_with_price)

# Определим признак с максимальной корреляцией
most_corr_feature = corr_with_price.index[1]  # [0] — это сама price
print(f"\nПризнак, наиболее сильно коррелирующий с ценой: {most_corr_feature}")

"""### Задание 4

Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования ([`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)). Не забудьте поставить значение параметра `drop_first` равным `True`.

Сколько получилось столбцов в таблице `data`?

*P.S. Числовые столбцы оставляем в таблице без изменений.*
"""

# your code here
# Закодируем категориальные признаки с помощью One-Hot Encoding
data_encoded = pd.get_dummies(data, drop_first=True)

# Выведем количество столбцов после кодирования
print(f"Количество столбцов после кодирования: {data_encoded.shape[1]}")

"""### Задание 5

Создайте матрицу `X`, содержащую все признаки, и не содержащую целевую переменную `price`. Также создайте вектор `y`, содержащий целевую переменную `price`.
"""

# your code here
# Матрица признаков (все столбцы, кроме 'price')
X = data.drop(columns=['price'])

# Целевая переменная (только 'price')
y = data['price']

print(f"Размерность X: {X.shape}")
print(f"Размерность y: {y.shape}")

"""Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной `0.3`.

При разбиении укажите `random_state = 42`.
"""

from sklearn.model_selection import train_test_split

# Разделение данных
Xtrain, Xtest, ytrain, ytest = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Проверим размеры полученных выборок
print(f"Размер обучающей выборки: {Xtrain.shape}, {ytrain.shape}")
print(f"Размер тестовой выборки: {Xtest.shape}, {ytest.shape}")

"""### Задание 6

Зачастую при использовании линейных моделей вещественные признаки масштабируются.  В этой задаче масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля `StandardScaler`.

*  Обучите (`fit`) scaler на тренировочных данных
*  Преобразуйте (`transform`) и трейн, и тест

После применения масштабирования матрица перестает быть объектом `pandas.DataFrame` - решите эту проблему.
"""

from sklearn.preprocessing import StandardScaler

# Убедимся, что все признаки числовые
Xtrain_num = Xtrain.select_dtypes(include=['float64', 'int64'])
Xtest_num = Xtest.select_dtypes(include=['float64', 'int64'])

# Создаём объект масштабирования
scaler = StandardScaler()

# Обучаем scaler на тренировочных данных и применяем к train и test
Xtrain_scaled = scaler.fit_transform(Xtrain_num)
Xtest_scaled = scaler.transform(Xtest_num)

# Преобразуем обратно в DataFrame
Xtrain_scaled = pd.DataFrame(Xtrain_scaled, columns=Xtrain_num.columns, index=Xtrain.index)
Xtest_scaled = pd.DataFrame(Xtest_scaled, columns=Xtest_num.columns, index=Xtest.index)

print("Масштабирование завершено успешно!")
print(f"Размер Xtrain_scaled: {Xtrain_scaled.shape}")
print(f"Размер Xtest_scaled: {Xtest_scaled.shape}")

"""### Задание 7

Обучите линейную регрессию на тренировочной выборке. Выведите *r2-score* на тренировочной и тестовой выборках.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# your code here
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Обучаем модель линейной регрессии
model = LinearRegression()
model.fit(Xtrain_scaled, ytrain)

# Предсказания
ytrain_pred = model.predict(Xtrain_scaled)
ytest_pred = model.predict(Xtest_scaled)

# Оценка качества по R²
r2_train = r2_score(ytrain, ytrain_pred)
r2_test = r2_score(ytest, ytest_pred)

print(f"R² на обучающей выборке: {r2_train:.4f}")
print(f"R² на тестовой выборке: {r2_test:.4f}")

"""### Задание 8

Выведите на экран веса, которые линейная регрессия присвоила признакам.

Какой признак имеет наибольший отрицательный вес? (наибольший по модулю среди всех отрицательных весов)
"""

# your code here
# Получаем веса (коэффициенты) признаков
weights = pd.Series(model.coef_, index=Xtrain_scaled.columns)

print("Веса признаков:")
print(weights.sort_values(ascending=False))

# Признак с наибольшим отрицательным весом
most_negative = weights[weights < 0].abs().idxmax()
print(f"\nПризнак с наибольшим отрицательным весом: {most_negative}")

"""## Попытка улучшить качество модели

Данная часть является творческой, и задания в ней немного сложнее, чем предыдущие.

Следующие вопросы не проверяются тестами.

### Задание 9

Как можно заметить из анализа корреляционной матрицы в задании 3, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы *мультиколлинеарности*. Различия в порядке коэффициентов, выявленные в предыдущей задаче, также свидетельствуют об этом. Для решения этой проблемы можно либо исключить некоторые признаки из модели (например, если признак линейно зависим с какими-то другими, его можно исключить из модели, т.е. удалить из матрицы объект-признак и заново обучить модель).

Удалите из матриц `Xtrain` и `Xtest` признак, который наиболее сильно коррелирует с остальными. Заново обучите модель и оцените её качество. Улучшилось ли качество модели?

Попробуйте удалить какой-то другой признак (можете попробовать несколько вариантов). Помогло ли это улучшить качество модели?
"""

# your code here
# Посмотрим на корреляцию признаков между собой
corr_matrix = Xtrain_scaled.corr().abs()

Xtrain_reduced = Xtrain_scaled.drop(columns=['x'])
Xtest_reduced = Xtest_scaled.drop(columns=['x'])

# Обучим модель заново
model2 = LinearRegression()
model2.fit(Xtrain_reduced, ytrain)

# Предсказания и оценка качества
ytrain_pred2 = model2.predict(Xtrain_reduced)
ytest_pred2 = model2.predict(Xtest_reduced)

r2_train2 = r2_score(ytrain, ytrain_pred2)
r2_test2 = r2_score(ytest, ytest_pred2)

print(f"\nПосле удаления признака '{most_corr_feature}':")
print(f"R² на обучающей выборке: {r2_train2:.4f}")
print(f"R² на тестовой выборке: {r2_test2:.4f}")

"""Иногда генерация новых признаков помогает модели лучше находить взаимосвязи между целевой переменной и признаками. Попробуйте придумать новые признаки и добавить их в модель.  

Помогло ли это улучшить качество модели?
"""

# your code here
# Скопируем исходные данные, чтобы не портить Xtrain_scaled
Xtrain_new = Xtrain_scaled.copy()
Xtest_new = Xtest_scaled.copy()

# Создадим новые признаки
Xtrain_new['volume'] = Xtrain_scaled['x'] * Xtrain_scaled['y'] * Xtrain_scaled['z']  # объём бриллианта
Xtest_new['volume'] = Xtest_scaled['x'] * Xtest_scaled['y'] * Xtest_scaled['z']

Xtrain_new['surface'] = 2 * (Xtrain_scaled['x']*Xtrain_scaled['y'] +
                             Xtrain_scaled['x']*Xtrain_scaled['z'] +
                             Xtrain_scaled['y']*Xtrain_scaled['z'])  # площадь поверхности
Xtest_new['surface'] = 2 * (Xtest_scaled['x']*Xtest_scaled['y'] +
                            Xtest_scaled['x']*Xtest_scaled['z'] +
                            Xtest_scaled['y']*Xtest_scaled['z'])

# Можно также добавить нелинейное взаимодействие
Xtrain_new['carat_squared'] = Xtrain_scaled['carat'] ** 2
Xtest_new['carat_squared'] = Xtest_scaled['carat'] ** 2

# Обучим модель снова
model3 = LinearRegression()
model3.fit(Xtrain_new, ytrain)

# Предсказания и метрики
ytrain_pred3 = model3.predict(Xtrain_new)
ytest_pred3 = model3.predict(Xtest_new)

r2_train3 = r2_score(ytrain, ytrain_pred3)
r2_test3 = r2_score(ytest, ytest_pred3)

print("После добавления новых признаков:")
print(f"R² на обучающей выборке: {r2_train3:.4f}")
print(f"R² на тестовой выборке: {r2_test3:.4f}")